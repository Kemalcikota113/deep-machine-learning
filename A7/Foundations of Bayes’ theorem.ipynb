{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df3727e4",
   "metadata": {},
   "source": [
    "# Assignment: Foundations of Bayesâ€™ theorem\n",
    "\n",
    "Fill out the blanks as per the instructions below.\n",
    "\n",
    "This assignment uses type hints, so make sure to stick to those.\n",
    "\n",
    "Whenever you need to fill in a blank, we used Python's ellipsis (`...`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7addde5",
   "metadata": {},
   "source": [
    "# Part 1 (A): Bayes' theorem with discrete random variables\n",
    "\n",
    "Here, we assume a discrete prior $P(\\theta)$, as well as a discrete probability distribution over a few i.i.d. observations.\n",
    "\n",
    "The goal is to manually implement functionals for computing marginal and conditional likelihoods/probability densities.\n",
    "\n",
    "You need to show that the posterior probability $P(\\theta|Y)$ is a proper probability mass function.\n",
    "Choose a different number of parameters and observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e7ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define our parameters theta and their probabilities (our prior belief):\n",
    "# A handful of thetas is enough.\n",
    "theta: list[int] = [...]\n",
    "theta_probs: list[float] = [...]\n",
    "\n",
    "# Here are our observations Y (don't change!):\n",
    "Y_obs = [0.5, 1.2]\n",
    "\n",
    "# Instead of assuming some (parameterized) distribution,\n",
    "# we hardcode the conditional likelihoods of Y given some theta.\n",
    "# Note that P(Y|\\theta) is a likelihood, so it does not represent\n",
    "# (necessarily) a valid probability density (i.e., values for each\n",
    "# \\theta do not necessarily have to sum to 1).\n",
    "P_Y_given_theta: dict[int, dict[float, float]] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bfcd27",
   "metadata": {},
   "source": [
    "## Define PMFs\n",
    "\n",
    "For convenience, we define the PMFs for $\\theta$ and $Y$ explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9e04636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change!\n",
    "def P_theta(val: float) -> float:\n",
    "    assert val in theta\n",
    "    idx = theta.index(val)\n",
    "    return theta_probs[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019a8211",
   "metadata": {},
   "source": [
    "## Define Functions\n",
    "\n",
    "for the likelihood $P(Y|\\theta)$, the prior $P(\\theta)$, and the evidence $P(Y)$.\n",
    "\n",
    "Recall that the evidence:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    P(Y)&=\\sum_i\\,P(Y|\\theta_i)\\times P(\\theta_i)\\nonumber.\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e4c26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood, P(Y|\\theta), now explicitly from our discrete definition:\n",
    "def likelihood(Y: list[float], t: float) -> float:\n",
    "    ...\n",
    "\n",
    "# The Evidence (in this assignment, it *is* computable):\n",
    "def P_Y(Y: list[float]) -> float:\n",
    "    ...\n",
    "\n",
    "# The posterior:\n",
    "def P_theta_given_Y(t: float, Y: list[float]) -> float:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da3f133",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type NoneType doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Don't change!\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m posterior_probs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mround\u001b[39m(P_theta_given_Y(t\u001b[38;5;241m=\u001b[39mt, Y\u001b[38;5;241m=\u001b[39mY_obs), ndigits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m theta]\n\u001b[0;32m      3\u001b[0m posterior_probs\n",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Don't change!\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m posterior_probs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mP_theta_given_Y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_obs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndigits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m theta]\n\u001b[0;32m      3\u001b[0m posterior_probs\n",
      "\u001b[1;31mTypeError\u001b[0m: type NoneType doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "# Don't change!\n",
    "posterior_probs = [round(P_theta_given_Y(t=t, Y=Y_obs), ndigits=5) for t in theta]\n",
    "posterior_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3298e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change! The result here needs to be ~1.0!\n",
    "print(sum(posterior_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32560e80",
   "metadata": {},
   "source": [
    "# Part 1(B): Bayes' theorem with continuous random variables\n",
    "\n",
    "-------------------------\n",
    "\n",
    "Now, we change our model a bit.\n",
    "Instead of assuming a small discrete set of possible values for $\\theta$, we will assume that this parameter follows a standard normal distribution.\n",
    "\n",
    "For our actual model, we will assume another normal distribution, where the standard deviation (scale) is fixed at $\\frac{3}{2}$ and the mean is set to $\\theta$: $N\\sim(\\mu=\\theta,\\sigma=\\frac{3}{2})$.\n",
    "\n",
    "We will re-use the previous observations.\n",
    "\n",
    "\n",
    "The evidence, defined continuously:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    P(Y)=\\int_{\\theta}\\,P(Y|t)\\times P(t)\\,d\\theta\\nonumber.\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3c74d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import norm\n",
    "\n",
    "# Our prior:\n",
    "def P_theta_continuous(val: float) -> float:\n",
    "    # Use norm.pdf() to compute this.\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82180d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "from typing import final\n",
    "\n",
    "\n",
    "# Realistically, our bounds could be -10,10 (or similar), but\n",
    "# scipy's quad allows to use infinity, so we'll use that, as\n",
    "# it's also closer to how we would formulate this mathematically.\n",
    "a, b = -np.inf, np.inf\n",
    "\n",
    "\n",
    "# Our model prototype that takes a single scale parameter that\n",
    "# will be held fixed for any subsequent likelihood computations.\n",
    "@final\n",
    "class Model:\n",
    "    \"\"\"Keep using this model class as-is, no need to change it.\"\"\"\n",
    "    def __init__(self, scale: float):\n",
    "        self.scale = scale\n",
    "    \n",
    "    def likelihood(self, x: float, mean: float) -> float:\n",
    "        return norm.pdf(x=x, loc=mean, scale=self.scale).item()\n",
    "    \n",
    "\n",
    "def likelihood_continuous(Y: list[float], t: float, model: Model) -> float:\n",
    "    ...\n",
    "\n",
    "def P_Y_continuous(Y: list[float], model: Model) -> float:\n",
    "    \"\"\"Use quad() to integrate.\"\"\"\n",
    "    ...\n",
    "\n",
    "\n",
    "def P_theta_given_Y_continuous(t: float, Y: list[float], evidence: float, model: Model) -> float:\n",
    "    ...\n",
    "\n",
    "\n",
    "# The goal of this function is to assert that our posterior is\n",
    "# a valid probability density that sums/integrates to 1.\n",
    "def P_theta_given_Y_continuous_integral(Y: list[float], model: Model) -> float:\n",
    "    evidence = P_Y_continuous(Y=Y, model=model)\n",
    "    func = lambda t: P_theta_given_Y_continuous(Y=Y, t=t, model=model, evidence=evidence)\n",
    "    return quad(func=func, a=a, b=b)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a73924",
   "metadata": {},
   "source": [
    "Now we show the amount of evidence, as well as that our posterior integrates to $\\approx1$:\n",
    "Also, we show the amount of (log-)evidence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c34f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change. Prints the log-evidence, as well as its integral (should be ~1.0).\n",
    "from math import log\n",
    "use_model = Model(scale=1.5)\n",
    "\n",
    "log(P_Y_continuous(Y=Y_obs, model=use_model)),\\\n",
    "P_theta_given_Y_continuous_integral(Y=Y_obs, model=use_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd0b42",
   "metadata": {},
   "source": [
    "### Find and use a better model\n",
    "\n",
    "Recall that our observations were fixed at $[0.5, 1.2]$ and we assumed our model would be a normal distribution with standard deviation $\\sigma=\\frac{3}{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86018ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35, 0.85)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_obs_arr = np.array(Y_obs)\n",
    "Y_obs_arr.std().item(), Y_obs_arr.mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb28220",
   "metadata": {},
   "source": [
    "However, we know that the standard deviation should likely be smaller to accommodate our data better.\n",
    "What we want to show here, is that a better model (here: same as previous but with a fixed standard deviation closer to $0.35$) produces a larger **evidence**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "# Use 'minimize_scalar' to find some optimal solution\n",
    "optimal_scale = ... # <- fill in the blank here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31db941e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.3604489040077827, 0.9999999999999998)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't change! Prints the log-evidence, as well as its integral (should be ~1.0).\n",
    "better_model = Model(scale=optimal_scale)\n",
    "\n",
    "log(P_Y_continuous(Y=Y_obs, model=better_model)),\\\n",
    "P_theta_given_Y_continuous_integral(Y=Y_obs, model=better_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c891f1",
   "metadata": {},
   "source": [
    "# Short evaluation (write 1-2 sentences per):\n",
    "\n",
    "1. How has the (log-)evidence changed using the optimal scale?\n",
    "2. In Bayesian terms, what does this result mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1073b2ed",
   "metadata": {},
   "source": [
    "**Answers**:\n",
    "\n",
    "1. ...\n",
    "2. ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
